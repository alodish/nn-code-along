{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd35416a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43ea9aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"\", train=True, download=True,\n",
    "                      transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST(\"\", train=False, download=True,\n",
    "                      transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82c6058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54cfc658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "# Visualize training data\n",
    "\n",
    "total = 0\n",
    "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1\n",
    "        total += 1\n",
    "        \n",
    "print(counter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbc1083f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 9.871666666666666\n",
      "1: 11.236666666666666\n",
      "2: 9.93\n",
      "3: 10.218333333333334\n",
      "4: 9.736666666666666\n",
      "5: 9.035\n",
      "6: 9.863333333333333\n",
      "7: 10.441666666666666\n",
      "8: 9.751666666666667\n",
      "9: 9.915000000000001\n"
     ]
    }
   ],
   "source": [
    "# Confirm equal representation of each class\n",
    "\n",
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "368d4623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ebdf490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64) # input 28x28px image \n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10) # 10 numbers (0-9) as final output\n",
    "        \n",
    "    def forward(self, x): # pass x through all Linear layers of Net\n",
    "        x = F.relu(self.fc1(x)) # rectified linear     \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)   \n",
    "        \n",
    "        \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb95a751",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((28, 28))\n",
    "X = X.view(-1, 28*28) # -1 = unknown output shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b947f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b66ab4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0031, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0060, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0053, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "EPOCHS = 3 # 3 passes through our entire dataset\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        # data is a batch of features and labels\n",
    "        X, y = data\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward() # back propogation over our parameters\n",
    "        optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2fee28d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.96\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, 28 * 28))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "print(\"Accuracy: \", round(correct/ total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "04fcfb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show an image to pass to our model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X[0].view(28, 28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd1d3cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "# Pass the number to our model and check answer\n",
    "\n",
    "print(torch.argmax(net(X[0].view(-1, 784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb40998",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
